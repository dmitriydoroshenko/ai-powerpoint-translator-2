import os
import json
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

SYSTEM_ROLE = (
    "You are a professional mobile game localizer. "
    "Task: Translate ONLY the text content within <a:t> tags in the provided XML to Simplified Chinese. "
    "Input: A JSON array of objects with 'id' and 'xml'. "
    "Output: Return a JSON object with a key 'translations' containing the array of objects, "
    "each having the original 'id' and the 'translated_text' containing the modified XML."
)

def translate_all(texts, batch_size=10):
    if not texts:
        print("‚ùå –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –ø—É—Å—Ç.")
        return []

    start_time = time.perf_counter()
    total_texts = len(texts)

    batches = [texts[i:i + batch_size] for i in range(0, total_texts, batch_size)]
    total_batches = len(batches)
    
    results = [None] * total_texts
    total_prompt_tokens = 0
    total_completion_tokens = 0
    
    print(f"\n{'='*40}")
    print(f"üöÄ –ó–ê–ü–£–°–ö –õ–û–ö–ê–õ–ò–ó–ê–¶–ò–ò (–ë–∞—Ç—á–∏–Ω–≥: {batch_size} —Å—Ç—Ä/–∑–∞–ø—Ä–æ—Å)")
    print(f"–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {total_texts} | –ë–∞—Ç—á–µ–π: {total_batches}")
    print(f"{'='*40}\n")

    with ThreadPoolExecutor(max_workers=10) as executor:
        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –±–∞—Ç—á–∏, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Ä—è–¥–æ–∫
        future_to_batch = {
            executor.submit(_translate_batch, [(i + start, texts[i + start]) 
            for i in range(len(batches[b_idx]))]): b_idx 
            for b_idx, start in enumerate(range(0, total_texts, batch_size))
        }
        
        completed_batches = 0
        for future in as_completed(future_to_batch):
            batch_results, usage = future.result()
            
            for idx, trans_text in batch_results:
                results[idx] = trans_text
            
            if usage:
                total_prompt_tokens += usage.prompt_tokens
                total_completion_tokens += usage.completion_tokens
            
            completed_batches += 1

            percent = (completed_batches / total_batches) * 100
            print(f"‚è≥ –ë–∞—Ç—á {completed_batches}/{total_batches} –∑–∞–≤–µ—Ä—à–µ–Ω ({percent:.1f}%) | "
                  f"–°—Ç—Ä–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {min(completed_batches * batch_size, total_texts)}")

    end_time = time.perf_counter()
    duration = end_time - start_time
    minutes, seconds = divmod(int(duration), 60)

    cost = (total_prompt_tokens * 1.75 / 1_000_000) + (total_completion_tokens * 14.00 / 1_000_000)

    print(f"\n{'='*40}")
    print(f"‚úÖ –ü–ï–†–ï–í–û–î –ó–ê–í–ï–†–®–ï–ù")
    print(f"‚è± –í—Ä–µ–º—è: {minutes} –º–∏–Ω. {seconds} —Å–µ–∫.")
    print(f"üìä –¢–æ–∫–µ–Ω—ã: –ü—Ä–æ–º–ø—Ç: {total_prompt_tokens} | –û—Ç–≤–µ—Ç: {total_completion_tokens}")
    print(f"üí∞ –û—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${cost:.4f}")
    print(f"{'='*40}\n")

    return results

def _translate_batch(batch):
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π [(index, text), ...]
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ [(index, translated_text), ...] –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–∫–µ–Ω–æ–≤.
    """
    try:
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏: —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ —Å ID –∏ —Ç–µ–∫—Å—Ç–æ–º
        payload = [{"id": idx, "xml": text} for idx, text in batch]
        
        response = client.chat.completions.create(
            model="gpt-5.2",
            messages=[
                {"role": "system", "content": SYSTEM_ROLE},
                {"role": "user", "content": json.dumps(payload, ensure_ascii=False)}
            ],
            response_format={"type": "json_object"},
            temperature=0.1
        )

        raw_content = response.choices[0].message.content
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –ø—É—Å—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –±–∞—Ç—á
        if raw_content is None:
            print("‚ö†Ô∏è API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç (None)")
            return [(idx, text) for idx, text in batch], response.usage

        # –¢–µ–ø–µ—Ä—å –ª–∏–Ω—Ç–µ—Ä –∑–Ω–∞–µ—Ç, —á—Ç–æ –∑–¥–µ—Å—å raw_content ‚Äî —ç—Ç–æ 100% str
        content = json.loads(raw_content)
        translated_data = content.get("translations", [])
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –ø–æ ID
        translations_map = {item['id']: item['translated_text'] for item in translated_data}
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ, –≤ –∫–æ—Ç–æ—Ä–æ–º –ø—Ä–∏—à–ª–∏ –¥–∞–Ω–Ω—ã–µ –≤ –±–∞—Ç—á
        result_batch = []
        for idx, original_text in batch:
            # –ï—Å–ª–∏ GPT –ø–æ—Ç–µ—Ä—è–ª –∫–∞–∫–æ–π-—Ç–æ ID, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
            translated_text = translations_map.get(idx, original_text)
            result_batch.append((idx, translated_text))
            
        return result_batch, response.usage

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞: {e}")
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—ã, —á—Ç–æ–±—ã —Å–∫—Ä–∏–ø—Ç –Ω–µ —É–ø–∞–ª
        return [(idx, text) for idx, text in batch], None